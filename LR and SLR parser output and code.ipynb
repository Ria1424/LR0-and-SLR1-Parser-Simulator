{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7qvOnJ0BpGx"
      },
      "source": [
        "This code accepts grammar as a .txt file, prints the states in its DFA in png format, the state transitions and generates the DFA as output. It also prints the LR(0) and SLR(1) parsing tables and whether the grammar is LR(0)/SLR(1) or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dpYINhm5pYF",
        "outputId": "8f91b739-3061-4dd5-d945-c34bd059e161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting termtables\n",
            "  Downloading termtables-0.2.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading termtables-0.2.4-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: termtables\n",
            "Successfully installed termtables-0.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install termtables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR6Rf0v9MUfi",
        "outputId": "8ab9ee18-2b5c-4e19-fb34-0a86db3d4c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the grammar file path (e.g., 'grammar.txt'): grammar6.txt\n",
            "---------------------------------------------------------------\n",
            "Augmented Grammar\n",
            "['X->.S', 'S->A', 'S->B', 'A->a', 'B->a']\n",
            "---------------------------------------------------------------\n",
            "Total States:  5\n",
            "State 0:\n",
            "  X->.S\n",
            "  S->.A\n",
            "  S->.B\n",
            "  A->.a\n",
            "  B->.a\n",
            "---------------------------------------------------------------\n",
            "State 1:\n",
            "  X->S.\n",
            "---------------------------------------------------------------\n",
            "State 2:\n",
            "  S->A.\n",
            "---------------------------------------------------------------\n",
            "State 3:\n",
            "  S->B.\n",
            "---------------------------------------------------------------\n",
            "State 4:\n",
            "  A->a.\n",
            "  B->a.\n",
            "---------------------------------------------------------------\n",
            "---------------------------------------------------------------\n",
            "Flow of the States (Transitions):\n",
            "From State 0 on symbol S -> Go to State 1\n",
            "From State 0 on symbol A -> Go to State 2\n",
            "From State 0 on symbol B -> Go to State 3\n",
            "From State 0 on symbol a -> Go to State 4\n",
            "---------------------------------------------------------------\n",
            "\n",
            " LR(0) Parsing Table:\n",
            "+---+--------+----+---+---+---+\n",
            "|   | $      | a  | A | B | S |\n",
            "+---+--------+----+---+---+---+\n",
            "| 0 |        | S4 | 2 | 3 | 1 |\n",
            "+---+--------+----+---+---+---+\n",
            "| 1 | Accept |    |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "| 2 | r1     | r1 |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "| 3 | r2     | r2 |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "| 4 | r4     | r4 |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "DFA has been generated and saved as 'dfa.png'.\n"
          ]
        }
      ],
      "source": [
        "import termtables as tt\n",
        "import graphviz\n",
        "\n",
        "# Adds a dot after \"->\" in a production rule string.\n",
        "def append_dot(a):\n",
        "    if \"ε\" in a:\n",
        "        return a  # Epsilon productions don't need a dot inside\n",
        "    return a.replace(\"->\", \"->.\")\n",
        "\n",
        "# Computes the closure of an item set for a given grammar, handling epsilon.\n",
        "def closure(a, prod):\n",
        "    temp = [a]\n",
        "    for it in temp:\n",
        "        if '.' not in it:\n",
        "            continue  # Skip items that don't have a dot\n",
        "        pos = it.index(\".\")\n",
        "        if pos != len(it) - 1:\n",
        "            jj = it[pos + 1]\n",
        "            if jj.isupper():  # Check if non-terminal\n",
        "                for k in prod:\n",
        "                    if k.startswith(jj + \"->\") and append_dot(k) not in temp:\n",
        "                        if k.endswith(\"->ε\") or k.endswith(\"->.ε\"):\n",
        "                            temp.append(k)  # Directly add epsilon production\n",
        "                        else:\n",
        "                            temp.append(append_dot(k))\n",
        "    return temp\n",
        "\n",
        "# Swaps the dot's position in an item to the next position.\n",
        "def swap(new, pos):\n",
        "    new = list(new)\n",
        "    if pos != len(new) - 1:\n",
        "        new[pos], new[pos + 1] = new[pos + 1], new[pos]\n",
        "        return \"\".join(new)\n",
        "    return \"\".join(new)\n",
        "\n",
        "# Extracts terminal symbols from the grammar.\n",
        "def get_terminals(gram):\n",
        "    terms = set()\n",
        "    for p in gram:\n",
        "        x1 = p.split('->')\n",
        "        for t in x1[1].strip():\n",
        "            if not t.isupper() and t != '.' and t != '' and t != 'ε':\n",
        "                terms.add(t)\n",
        "    terms.add('$')\n",
        "    return terms\n",
        "\n",
        "# Extracts non-terminal symbols from the grammar.\n",
        "def get_non_terminals(gram):\n",
        "    non_terms = set()\n",
        "    for p in gram:\n",
        "        non_terms.add(p.split('->')[0])\n",
        "    return non_terms\n",
        "\n",
        "# Calculates the goto set for an item and a symbol.\n",
        "def goto1(x1, prod):\n",
        "    if '.' not in x1:\n",
        "        return []  # Return an empty list if the dot is not found to avoid errors\n",
        "    pos = x1.index(\".\")\n",
        "    if pos != len(x1) - 1:\n",
        "        kk = swap(x1, pos)\n",
        "        return closure(kk, prod)\n",
        "    return []\n",
        "\n",
        "# Main code to execute LR(0) related functions\n",
        "if __name__ == '__main__':\n",
        "    grammar_file = input(\"Enter the grammar file path (e.g., 'grammar.txt'): \")\n",
        "    prod = []\n",
        "    set_of_items = []\n",
        "    c = []\n",
        "\n",
        "    with open(grammar_file, 'r') as fp:\n",
        "        for line in fp.readlines():\n",
        "            prod.append(line.strip())\n",
        "\n",
        "    start_symbol = prod[0].split('->')[0]\n",
        "    augmented_start = f\"X->{start_symbol}\"\n",
        "    prod.insert(0, append_dot(augmented_start))\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(\"Augmented Grammar\")\n",
        "    print(prod)\n",
        "\n",
        "    prod_num = {prod[i]: i for i in range(1, len(prod))}\n",
        "\n",
        "    j = closure(append_dot(augmented_start), prod)\n",
        "    set_of_items.append(j)\n",
        "\n",
        "    state_numbers = {}\n",
        "    dfa_prod = {}\n",
        "    items = 0\n",
        "\n",
        "    while set_of_items:\n",
        "        jk = set_of_items.pop(0)\n",
        "        c.append(jk)\n",
        "        state_numbers[str(jk)] = items\n",
        "        items += 1\n",
        "\n",
        "        symbols = sorted(get_terminals(prod).union(get_non_terminals(prod)), key=lambda x: (x != 'S', x))\n",
        "        for sym in symbols:\n",
        "            new_items = set()\n",
        "            for item in jk:\n",
        "                if '.' in item:\n",
        "                    pos = item.index('.')\n",
        "                    if pos + 1 < len(item) and item[pos + 1] == sym:\n",
        "                        moved_item = swap(item, pos)\n",
        "                        new_items.update(closure(moved_item, prod))\n",
        "\n",
        "            if new_items:\n",
        "                new_items = list(new_items)\n",
        "                if new_items not in c and new_items not in set_of_items:\n",
        "                    set_of_items.append(new_items)\n",
        "                dfa_prod[f\"{state_numbers[str(jk)]} {sym}\"] = new_items\n",
        "\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(\"Total States: \", len(c))\n",
        "    for i, items in enumerate(c):\n",
        "        print(f\"State {i}:\")\n",
        "        for item in items:\n",
        "            print(f\"  {item}\")\n",
        "        print(\"---------------------------------------------------------------\")\n",
        "\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(\"Flow of the States (Transitions):\")\n",
        "    for key, value in dfa_prod.items():\n",
        "        current_state, transition = key.split()\n",
        "        next_state = state_numbers.get(str(value), None)\n",
        "        if next_state is not None:\n",
        "            print(f\"From State {current_state} on symbol {transition} -> Go to State {next_state}\")\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "\n",
        "# Generate LR(0) Parsing Table\n",
        "table = []\n",
        "term = sorted(list(get_terminals(prod)))\n",
        "non_term = sorted(list(get_non_terminals(prod) - {'X'}))\n",
        "header = [''] + term + non_term\n",
        "table.append(header)\n",
        "\n",
        "table_dic = {}\n",
        "\n",
        "for i in range(len(c)):\n",
        "    data = [''] * (len(term) + len(non_term))\n",
        "    samp = {}\n",
        "\n",
        "    # Action\n",
        "    for item in c[i]:\n",
        "        if '.' in item and item.index('.') == len(item) - 1:  # If dot is at the end\n",
        "            # This indicates a reduce move\n",
        "            production = item.replace('.', '')\n",
        "            if production == \"X->S\":  # Check for Accept state\n",
        "                data[term.index('$')] = 'Accept'\n",
        "                samp['$'] = 'Accept'\n",
        "            elif production in prod_num:\n",
        "                reduce_index = prod_num[production]\n",
        "                for t in term:\n",
        "                    data[term.index(t)] = f'r{reduce_index}'  # Add reduce move\n",
        "                    samp[t] = f'r{reduce_index}'\n",
        "\n",
        "    for j in dfa_prod:\n",
        "        current_state, symbol = j.split()\n",
        "        if int(current_state) == i:\n",
        "            if symbol in term:\n",
        "                data[term.index(symbol)] = 'S' + str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "                samp[symbol] = 'S' + str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "\n",
        "    # Goto\n",
        "    for j in dfa_prod:\n",
        "        current_state, symbol = j.split()\n",
        "        if int(current_state) == i and symbol in non_term:\n",
        "            data[len(term) + non_term.index(symbol)] = str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "            samp[symbol] = str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "\n",
        "    table_dic[i] = samp\n",
        "    table.append([i] + data)\n",
        "\n",
        "# Print LR(0) parsing table using termtables\n",
        "final_table = tt.to_string(data=table, style=tt.styles.ascii_thin_double, padding=(0, 1))\n",
        "print(\"\\n LR(0) Parsing Table:\")\n",
        "print(final_table)\n",
        "\n",
        "# Printing DFA\n",
        "def visualize_dfa(dfa_prod, state_numbers):\n",
        "    dot = graphviz.Digraph(format='png')\n",
        "    dot.attr(rankdir='LR', size='8,5')\n",
        "    dot.attr('node', shape='circle')\n",
        "\n",
        "    for key, value in dfa_prod.items():\n",
        "        current_state, transition = key.split()\n",
        "        next_state = state_numbers.get(str(value), None)\n",
        "        if next_state is not None:\n",
        "            dot.edge(f'S{current_state}', f'S{next_state}', label=transition)\n",
        "\n",
        "    dot.render('dfa', view=True, cleanup=True)\n",
        "    print(\"DFA has been generated and saved as 'dfa.png'.\")\n",
        "\n",
        "visualize_dfa(dfa_prod, state_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hygSCOV4DPXL",
        "outputId": "d5ec67cb-af45-4d51-e3e2-b40c314af6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conflict in State 4: Reduce-Reduce Conflict\n",
            "The grammar is NOT LR(0) due to conflicts.\n"
          ]
        }
      ],
      "source": [
        "# Function to check if the grammar is LR(0) and identify conflicts\n",
        "def check_lr0_grammar(c, term):\n",
        "    lr0_conflict = False\n",
        "    for i, state in enumerate(c):\n",
        "        shift_reduce_conflict = False\n",
        "        reduce_reduce_conflict = False\n",
        "\n",
        "        actions = []\n",
        "        for item in state:\n",
        "            if '.' in item and item.index('.') == len(item) - 1:  # If dot is at the end (reduce)\n",
        "                actions.append('reduce')\n",
        "            else:\n",
        "                actions.append('shift')\n",
        "\n",
        "        # Check for conflicts\n",
        "        if actions.count('reduce') > 1:\n",
        "            reduce_reduce_conflict = True\n",
        "        if 'shift' in actions and 'reduce' in actions:\n",
        "            shift_reduce_conflict = True\n",
        "\n",
        "        # Print conflicts if any\n",
        "        if reduce_reduce_conflict:\n",
        "            print(f\"Conflict in State {i}: Reduce-Reduce Conflict\")\n",
        "            lr0_conflict = True\n",
        "        if shift_reduce_conflict:\n",
        "            print(f\"Conflict in State {i}: Shift-Reduce Conflict\")\n",
        "            lr0_conflict = True\n",
        "\n",
        "    if not lr0_conflict:\n",
        "        print(\"The grammar is LR(0).\")\n",
        "    else:\n",
        "        print(\"The grammar is NOT LR(0) due to conflicts.\")\n",
        "\n",
        "# Function call\n",
        "check_lr0_grammar(c, term)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcuhjnBhFPpK",
        "outputId": "d5066d0c-5c40-4b44-8814-290d1285e1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLLOW sets:\n",
            "S: {'$'}\n",
            "A: {'$'}\n",
            "B: {'$'}\n",
            "Conflict in State 4 on symbol '$': Reduce-Reduce or Shift-Reduce Conflict\n",
            "\n",
            "SLR(1) Parsing Table:\n",
            "+---+--------+----+---+---+---+\n",
            "|   | $      | a  | A | B | S |\n",
            "+---+--------+----+---+---+---+\n",
            "| 0 |        | S4 | 2 | 3 | 1 |\n",
            "+---+--------+----+---+---+---+\n",
            "| 1 | Accept |    |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "| 2 | r1     |    |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "| 3 | r2     |    |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "| 4 | r4     |    |   |   |   |\n",
            "+---+--------+----+---+---+---+\n",
            "The grammar is NOT SLR(1) due to conflicts.\n"
          ]
        }
      ],
      "source": [
        "# Function to compute FIRST sets\n",
        "def compute_first_sets(prod):\n",
        "    first_sets = {nt: set() for nt in get_non_terminals(prod)}\n",
        "    change = True\n",
        "\n",
        "    while change:\n",
        "        change = False\n",
        "        for rule in prod:\n",
        "            head, body = rule.split('->')\n",
        "            body = body.strip()\n",
        "            if body == 'ε':\n",
        "                if 'ε' not in first_sets[head]:\n",
        "                    first_sets[head].add('ε')\n",
        "                    change = True\n",
        "            else:\n",
        "                for symbol in body:\n",
        "                    if symbol.isupper():  # Non-terminal\n",
        "                        original_length = len(first_sets[head])\n",
        "                        first_sets[head].update(first_sets[symbol] - {'ε'})\n",
        "                        if 'ε' in first_sets[symbol]:\n",
        "                            continue\n",
        "                        else:\n",
        "                            break\n",
        "                    else:  # Terminal\n",
        "                        if symbol not in first_sets[head]:\n",
        "                            first_sets[head].add(symbol)\n",
        "                            change = True\n",
        "                        break\n",
        "                else:\n",
        "                    if 'ε' not in first_sets[head]:\n",
        "                        first_sets[head].add('ε')\n",
        "                        change = True\n",
        "\n",
        "    return first_sets\n",
        "\n",
        "# Function to compute FOLLOW sets\n",
        "def compute_follow_sets(prod, start_symbol):\n",
        "    follow_sets = {nt: set() for nt in get_non_terminals(prod)}\n",
        "    follow_sets[start_symbol].add('$')  # Start symbol always has '$'\n",
        "\n",
        "    first_sets = compute_first_sets(prod)\n",
        "    change = True\n",
        "\n",
        "    while change:\n",
        "        change = False\n",
        "        for rule in prod:\n",
        "            head, body = rule.split('->')\n",
        "            body = body.strip()\n",
        "\n",
        "            for i, symbol in enumerate(body):\n",
        "                if symbol.isupper():  # If it's a non-terminal\n",
        "                    if i + 1 < len(body):\n",
        "                        next_symbol = body[i + 1]\n",
        "                        if next_symbol.isupper():\n",
        "                            original_length = len(follow_sets[symbol])\n",
        "                            follow_sets[symbol].update(first_sets[next_symbol] - {'ε'})\n",
        "                            if 'ε' in first_sets[next_symbol]:\n",
        "                                follow_sets[symbol].update(follow_sets[head])\n",
        "                            if len(follow_sets[symbol]) > original_length:\n",
        "                                change = True\n",
        "                        else:\n",
        "                            if next_symbol not in follow_sets[symbol]:\n",
        "                                follow_sets[symbol].add(next_symbol)\n",
        "                                change = True\n",
        "                    else:\n",
        "                        original_length = len(follow_sets[symbol])\n",
        "                        follow_sets[symbol].update(follow_sets[head])\n",
        "                        if len(follow_sets[symbol]) > original_length:\n",
        "                            change = True\n",
        "\n",
        "    return follow_sets\n",
        "\n",
        "# Function to generate and print the SLR(1) parsing table and identify conflicts\n",
        "def generate_slr1_table(c, term, non_term, prod, prod_num, follow_sets):\n",
        "    table = []\n",
        "    header = [''] + term + non_term\n",
        "    table.append(header)\n",
        "    table_dic = {}  # Dictionary to store the parsing table\n",
        "    slr1_conflict = False\n",
        "\n",
        "    for i in range(len(c)):\n",
        "        data = [''] * (len(term) + len(non_term))\n",
        "        samp = {}\n",
        "\n",
        "        # Action\n",
        "        for item in c[i]:\n",
        "            if '.' in item and item.index('.') == len(item) - 1:  # If dot is at the end (reduce)\n",
        "                production = item.replace('.', '')\n",
        "                if production == \"X->S\":  # Check for Accept state\n",
        "                    data[term.index('$')] = 'Accept'\n",
        "                    samp['$'] = 'Accept'\n",
        "                elif production in prod_num:\n",
        "                    reduce_index = prod_num[production]\n",
        "                    for t in follow_sets[production.split('->')[0]]:  # Use FOLLOW set for the reduce\n",
        "                        if data[term.index(t)] != '' and data[term.index(t)] != f'r{reduce_index}':\n",
        "                            print(f\"Conflict in State {i} on symbol '{t}': Reduce-Reduce or Shift-Reduce Conflict\")\n",
        "                            slr1_conflict = True\n",
        "                        data[term.index(t)] = f'r{reduce_index}'  # Add reduce move\n",
        "                        samp[t] = f'r{reduce_index}'\n",
        "\n",
        "        for j in dfa_prod:\n",
        "            current_state, symbol = j.split()\n",
        "            if int(current_state) == i:\n",
        "                if symbol in term:\n",
        "                    if data[term.index(symbol)] != '' and data[term.index(symbol)] != 'S' + str(state_numbers.get(str(dfa_prod[j]), '')):\n",
        "                        print(f\"\\nConflict in State {i} on symbol '{symbol}'\")\n",
        "                        slr1_conflict = True\n",
        "                    data[term.index(symbol)] = 'S' + str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "                    samp[symbol] = 'S' + str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "\n",
        "        # Goto\n",
        "        for j in dfa_prod:\n",
        "            current_state, symbol = j.split()\n",
        "            if int(current_state) == i and symbol in non_term:\n",
        "                data[len(term) + non_term.index(symbol)] = str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "                samp[symbol] = str(state_numbers.get(str(dfa_prod[j]), ''))\n",
        "\n",
        "        table_dic[i] = samp\n",
        "        table.append([i] + data)\n",
        "\n",
        "    # Print the SLR(1) table using termtables\n",
        "    final_table = tt.to_string(data=table, style=tt.styles.ascii_thin_double, padding=(0, 1))\n",
        "    print(\"\\nSLR(1) Parsing Table:\")\n",
        "    print(final_table)\n",
        "\n",
        "    if not slr1_conflict:\n",
        "        print(\"The grammar is SLR(1).\")\n",
        "    else:\n",
        "        print(\"The grammar is NOT SLR(1) due to conflicts.\")\n",
        "\n",
        "# Main code to compute FOLLOW sets and generate the SLR(1) table\n",
        "start_symbol = prod[1].split('->')[0]  # Use the first non-augmented production's LHS as the start symbol\n",
        "follow_sets = compute_follow_sets(prod, start_symbol)\n",
        "print(\"FOLLOW sets:\")\n",
        "for nt, follows in follow_sets.items():\n",
        "    if nt != 'X':  # Skip printing the FOLLOW set for the augmented non-terminal 'X'\n",
        "        print(f\"{nt}: {follows}\")\n",
        "\n",
        "# Call the function to generate and print the SLR(1) table\n",
        "generate_slr1_table(c, term, non_term, prod, prod_num, follow_sets)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
